{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AgcLtGAR8ZRO",
        "801ypNKd2bfD",
        "fqv0hex8SNFj",
        "RfvulChuTRjM",
        "eEeO4NBwKJVC",
        "WcqratCbZOzt",
        "3FPf7RgDn6Wm",
        "I66ZF3hPsivB",
        "Llr4a15rptwL"
      ],
      "authorship_tag": "ABX9TyN0KKL9I3XKvKsXtyjXwxek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artursanntos/gemini_api_guide/blob/main/Cria%C3%A7%C3%A3o_de_Comunica%C3%A7%C3%A3o_com_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criação de Comunicação com LLM\n",
        "Roteiro para criação de comunicação com LLM utilizando API do Gemini.\n",
        "\n",
        "- [Criação via API Studio](https://aistudio.google.com/apikey)\n",
        "- [Criação via Google Cloud Platform](https://console.cloud.google.com/)\n",
        "\n",
        "**Obs:** Este roteiro está em Python, mas todos os links possuem versões em JavaScript!"
      ],
      "metadata": {
        "id": "6SgSvGBvzyss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existem muitas formas de utilizar a API do Google e este arquivo aborda apenas a utilização padrão da api do gemini.\n",
        "- Por exemplo, o langchain tem um wrapper sobre a API do Gemini ([Langchain ChatGoogleGenerativeAI](https://python.langchain.com/docs/integrations/chat/google_generative_ai/))\n",
        "\n",
        "\n",
        "Obs: **Guardem suas chaves de API em um arquivo .env** e coloquem no .gitignore."
      ],
      "metadata": {
        "id": "ikJ0KR9HwkF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apenas importando o método de acesso aos Secrets do Collab\n",
        "# No typescript, procure como gerenciar variáveis de ambiente\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "X7K3_m0F18pW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Primeira chamada\n",
        "Localmente, instale via `pip install google-genai`\n",
        "\n"
      ],
      "metadata": {
        "id": "AgcLtGAR8ZRO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTV-jfcRyHtn",
        "outputId": "d9be06fc-f97c-4530-a9b6-3201d58ac6a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O Sport Club do Recife é um clube de futebol brasileiro da cidade de Recife, Pernambuco, com uma rica história e uma apaixonada torcida, sendo um dos maiores e mais tradicionais do Nordeste.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=\"Defina o Sport Recife em uma frase\",\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Detalhamento do Response"
      ],
      "metadata": {
        "id": "801ypNKd2bfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Referência da API](https://ai.google.dev/api/generate-content#v1beta.GenerateContentResponse)"
      ],
      "metadata": {
        "id": "FH5v_Bf2FFiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "candidates=\n",
        "[\n",
        "  Candidate(content=Content(\n",
        "  parts=[Part(video_metadata=None,\n",
        "      thought=None, inline_data=None, code_execution_result=None,\n",
        "      executable_code=None, file_data=None, function_call=None,\n",
        "      function_response=None,\n",
        "      text='O Sport Recife é um clube de futebol\n",
        "      tradicional de Pernambuco, conhecido por sua camisa rubro-negra e uma\n",
        "      história rica em conquistas regionais e nacionais.\\n'\n",
        "      )], role='model'),\n",
        "  citation_metadata=None,\n",
        "  finish_message=None,\n",
        "  token_count=None,\n",
        "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
        "  url_context_metadata=None,\n",
        "  avg_logprobs=-0.21691273197983252,\n",
        "  grounding_metadata=None, index=None, logprobs_result=None,\n",
        "  safety_ratings=None\n",
        ")]\n",
        "create_time=None\n",
        "response_id=None\n",
        "model_version='gemini-2.0-flash'\n",
        "prompt_feedback=None\n",
        "usage_metadata=GenerateContentResponseUsageMetadata\n",
        "    (\n",
        "      cache_tokens_details=None,\n",
        "      cached_content_token_count=None,\n",
        "      candidates_token_count=33,\n",
        "      candidates_tokens_details=\n",
        "        [\n",
        "          ModalityTokenCount(modality=<MediaModality.TEXT:\n",
        "          'TEXT'>, token_count=33)\n",
        "        ],\n",
        "      prompt_token_count=8,\n",
        "      prompt_tokens_details=\n",
        "        [\n",
        "          ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=8)\n",
        "        ],\n",
        "      thoughts_token_count=None,\n",
        "      tool_use_prompt_token_count=None,\n",
        "      tool_use_prompt_tokens_details=None, total_token_count=41, traffic_type=None\n",
        "    )\n",
        "automatic_function_calling_history=[]\n",
        "parsed=None\n",
        "```"
      ],
      "metadata": {
        "id": "G_ZbQm_P2T7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roles e Formatos de Mensagens"
      ],
      "metadata": {
        "id": "yL4tz2McP2al"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formato padrão do Gemini"
      ],
      "metadata": {
        "id": "fqv0hex8SNFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Gemini, por padrão, as mensagens se organizam com o seguinte formato:\n",
        "\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"role\": string\n",
        "  \"parts\": [\n",
        "    \"text\": string,\n",
        "    \"inline_data\": (imagem, arquivos...)\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "Temos essencialmente duas roles (papéis) na troca de mensagens:\n",
        "1. `user`\n",
        "2. `model`\n",
        "\n",
        "Esse é o formato considerado neste roteiro.\n",
        "\n",
        "Para entender como estruturar melhor o Parts, visite [esta referência](https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/Content)."
      ],
      "metadata": {
        "id": "_GAd5bLARGz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formato compatível com a OpenAI"
      ],
      "metadata": {
        "id": "RfvulChuTRjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também é disponibilizado um formato compatível com o padrão da OpenAI."
      ],
      "metadata": {
        "id": "-mGO7MqETgsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temos essencialmente três roles (papéis) na troca de mensagens:\n",
        "\n",
        "1. `user`\n",
        "2. `assistant`\n",
        "3. `system`\n",
        "\n",
        "Abaixo um exemplo de estrutura de mensagem"
      ],
      "metadata": {
        "id": "pfo4c8w7UCki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=userdata.get(\"GOOGLE_API_KEY\"),\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain to me how AI works\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "vzXIO2LDROS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8008bbc9-fe4d-40a1-a088-124ed8085da4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's break down how AI works in a way that's easy to understand.  The term \"AI\" is quite broad, so I'll focus on the core concepts and common techniques.\n",
            "\n",
            "**What is AI, at its core?**\n",
            "\n",
            "At its most basic, Artificial Intelligence (AI) is about creating computer systems that can perform tasks that typically require human intelligence.  This includes things like:\n",
            "\n",
            "*   **Learning:** Adapting and improving from experience.\n",
            "*   **Problem-solving:** Figuring out how to achieve a goal.\n",
            "*   **Decision-making:** Choosing the best course of action.\n",
            "*   **Understanding language:** Processing and interpreting human language.\n",
            "*   **Recognizing patterns:** Identifying meaningful structures in data.\n",
            "\n",
            "**Key Approaches to Achieving AI**\n",
            "\n",
            "There are many different approaches to building AI systems, but here are some of the most important:\n",
            "\n",
            "1.  **Machine Learning (ML):**\n",
            "\n",
            "    *   **The Idea:** Instead of explicitly programming a computer to do something, we *teach* it to learn from data.  Think of it like showing a child lots of pictures of cats and dogs until they can tell the difference themselves.\n",
            "\n",
            "    *   **How it Works:**\n",
            "\n",
            "        *   **Data:**  ML algorithms need a lot of data to learn from. This data is used to train the model.\n",
            "        *   **Algorithms:** There are many different ML algorithms, each suited for different types of tasks. Some common examples include:\n",
            "            *   **Supervised Learning:**  The algorithm is given labeled data (e.g., pictures of cats labeled \"cat\" and pictures of dogs labeled \"dog\").  It learns to predict the correct label for new, unseen data.  Examples: classification (categorizing things) and regression (predicting numerical values).\n",
            "            *   **Unsupervised Learning:** The algorithm is given unlabeled data and tries to find patterns and structures within it. Examples: clustering (grouping similar data points together) and dimensionality reduction (simplifying data while preserving important information).\n",
            "            *   **Reinforcement Learning:** The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions. It learns to maximize its rewards over time. Think of training a dog with treats.  Examples: training robots to perform tasks, playing games.\n",
            "        *   **Model:**  The algorithm uses the data to create a model. A model is essentially a mathematical representation of the patterns it has learned from the data.\n",
            "        *   **Training:** The process of feeding the data to the algorithm to create the model.\n",
            "        *   **Prediction/Inference:** Once the model is trained, it can be used to make predictions or decisions on new data.\n",
            "\n",
            "    *   **Example:**  Spam filtering.  An ML algorithm is trained on a dataset of emails labeled as \"spam\" or \"not spam.\"  It learns to identify patterns (e.g., certain words, phrases, sender information) that are indicative of spam.  When a new email arrives, the algorithm uses its model to predict whether it's spam or not.\n",
            "\n",
            "2.  **Deep Learning (DL):**\n",
            "\n",
            "    *   **The Idea:**  A subfield of machine learning that uses artificial neural networks with many layers (hence \"deep\") to analyze data.  Inspired by the structure of the human brain.\n",
            "\n",
            "    *   **How it Works:**\n",
            "\n",
            "        *   **Neural Networks:**  These are complex networks of interconnected nodes (neurons) that process information.  Each connection between neurons has a weight associated with it, which represents the strength of the connection.\n",
            "        *   **Layers:**  Deep learning networks have many layers of neurons, allowing them to learn complex, hierarchical features from data.  For example, in image recognition, the first layers might learn to detect edges and corners, while later layers learn to recognize objects.\n",
            "        *   **Training:**  Deep learning models are trained using massive amounts of data and powerful computing resources (often GPUs).  The training process involves adjusting the weights of the connections between neurons to minimize the error between the model's predictions and the actual values.\n",
            "\n",
            "    *   **Why it's Powerful:** Deep learning has achieved remarkable success in areas like image recognition, natural language processing, and speech recognition because it can automatically learn complex features from data without the need for manual feature engineering.\n",
            "\n",
            "    *   **Example:**  Image recognition.  A deep learning model can be trained on a dataset of millions of images to recognize different objects, such as cats, dogs, cars, and airplanes.\n",
            "\n",
            "3.  **Natural Language Processing (NLP):**\n",
            "\n",
            "    *   **The Idea:**  Enabling computers to understand, interpret, and generate human language.\n",
            "\n",
            "    *   **How it Works:** NLP uses a combination of techniques from computer science, linguistics, and machine learning. Key tasks include:\n",
            "\n",
            "        *   **Text analysis:**  Breaking down text into its component parts (words, sentences, etc.) and analyzing its structure and meaning.\n",
            "        *   **Sentiment analysis:**  Determining the emotional tone of a piece of text (e.g., positive, negative, neutral).\n",
            "        *   **Machine translation:**  Translating text from one language to another.\n",
            "        *   **Text generation:**  Generating new text, such as summaries, articles, or dialogue.\n",
            "        *   **Question answering:**  Answering questions posed in natural language.\n",
            "\n",
            "    *   **Example:**  Chatbots.  NLP is used to understand the user's input and generate appropriate responses.\n",
            "\n",
            "4.  **Rule-Based Systems (Expert Systems):**\n",
            "\n",
            "    *   **The Idea:**  Using a set of predefined rules to make decisions or solve problems.\n",
            "\n",
            "    *   **How it Works:**\n",
            "\n",
            "        *   **Knowledge Base:** A collection of facts and rules about a specific domain.\n",
            "        *   **Inference Engine:** A program that applies the rules in the knowledge base to the available data to draw conclusions or make recommendations.\n",
            "\n",
            "    *   **Example:**  Medical diagnosis.  An expert system could use a knowledge base of medical knowledge and a set of rules to diagnose a patient's illness based on their symptoms.\n",
            "\n",
            "**The AI Development Process (Simplified)**\n",
            "\n",
            "1.  **Define the Problem:** Clearly identify what you want the AI to achieve. What task do you want it to perform? What data do you have available?\n",
            "2.  **Gather and Prepare Data:**  Collect the data needed to train the AI model. Clean and preprocess the data to ensure it's in a suitable format.  This is often the most time-consuming step.\n",
            "3.  **Choose an Algorithm/Technique:** Select the appropriate AI algorithm or technique based on the problem and the available data.\n",
            "4.  **Train the Model:**  Feed the data into the algorithm to train the model.\n",
            "5.  **Evaluate the Model:**  Assess the performance of the model on a separate dataset (the \"test set\") to ensure it generalizes well to new data.\n",
            "6.  **Deploy the Model:**  Integrate the model into a real-world application.\n",
            "7.  **Monitor and Retrain:**  Continuously monitor the performance of the model and retrain it as needed to maintain its accuracy and effectiveness.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "*   **Data is King:** The quality and quantity of data are crucial for the success of AI systems.\n",
            "*   **Bias:** AI models can inherit biases from the data they are trained on, leading to unfair or discriminatory outcomes.  It's important to be aware of and mitigate bias in AI systems.\n",
            "*   **Explainability:**  Understanding how an AI model makes its decisions can be challenging, especially with complex models like deep neural networks.  Explainable AI (XAI) is a growing field that aims to make AI models more transparent and understandable.\n",
            "*   **Ethics:**  AI raises important ethical considerations, such as privacy, security, and the potential for job displacement.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "AI involves creating systems that can perform tasks requiring human intelligence.  Machine learning, particularly deep learning, is a dominant approach, relying on algorithms to learn from data. Natural language processing allows computers to understand and generate human language. The key is to provide the AI system with the right data and algorithms to learn and improve over time.\n",
            "\n",
            "I hope this explanation is helpful!  Let me know if you have any more questions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo configurações do modelo"
      ],
      "metadata": {
        "id": "SGjk2RwL8Uj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para controlar melhor as chamadas e configurar parâmetros, é necessário instanciar um **GenerateContentConfig** e adicionar como configuração às chamadas do modelo."
      ],
      "metadata": {
        "id": "MhKrJ0cfGMKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "generation_config = types.GenerateContentConfig(\n",
        "        system_instruction=\"Você é um modelo torcedor do Sport Recife. Todas as suas respostas devem ser favoráveis ao Sport.\",\n",
        "        max_output_tokens=256,\n",
        "        temperature=0.5,\n",
        "        top_k=40,\n",
        "        top_p=0.95,\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    config=generation_config,\n",
        "    contents=\"Qual o melhor time do Nordeste?\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTQhbDf22gTk",
        "outputId": "55a30810-e821-44a8-bfbe-6acea5ff3984"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Essa é fácil! O melhor time do Nordeste é, sem sombra de dúvidas, o Sport Recife! Maior campeão do Nordeste, único campeão da Copa do Brasil, o Leão da Ilha é gigante!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Detalhamento dos parâmetros configuráveis com GenerateContentConfig"
      ],
      "metadata": {
        "id": "eEeO4NBwKJVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Referência da API (Todos os parâmetros)](https://ai.google.dev/api/generate-content#v1beta.GenerationConfig)\n",
        "\n",
        "Principais parâmetros:\n",
        "- **system_instruction**: Prompt do Sistema do modelo. O modelo dá mais prioridade aos comandos detalhados neste campo.\n",
        "- **max_output_tokens**: Máximo de tokens que o modelo pode usar na resposta.\n",
        "- **temperature**: Controla a aleatoriedade (criatividade) do modelo. Varia de [0.0, 2.0], sendo valores menores mais determinístico e os maiores mais criativos.\n",
        "- **top_k**: Controla entre quantas palavras (na verdade tokens) o modelo pode escolher. Ou seja, se o top_k for 40, ele vai sempre escolher entre as 40 palavras mais prováveis.\n",
        "- **top_p**: Também controla a criatividade, variando entre [0.0, 1.0]. Quanto menor o top_p, mais o modelo \"joga seguro\". Quanto maior, mais ele se permite inventar e trazer palavras diferentes.\n",
        "- **response_modalities**: Indica o formato de resposta, se deixado em branco, fica padronizado para ser TEXTO\n",
        "- **response_mime_type**: Campo destinado a definir o tipo de saída, sendo o padrão `text/plain`, mas podendo ser `application/json` e também um `text/x.enum`.\n",
        "- **response_schema**: Caso você defina o mime type como JSON, aqui você pode definir o modelo de resposta."
      ],
      "metadata": {
        "id": "qw3lRTHEKQIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming de Respostas"
      ],
      "metadata": {
        "id": "WcqratCbZOzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "generation_config = types.GenerateContentConfig(\n",
        "        max_output_tokens=300,\n",
        "        temperature=0.5,\n",
        "        top_k=40,\n",
        "        top_p=0.95\n",
        ")\n",
        "\n",
        "response = client.models.generate_content_stream(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[\"Resuma como o Sport ganhou a copa do Brasil de 2008\"],\n",
        "    config=generation_config\n",
        ")\n",
        "for chunk in response:\n",
        "    print(chunk.text, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uANPMqTsZRVY",
        "outputId": "a36ba9b1-0673-471f-db1c-bd4e1eb5fed5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O Sport Club do Recife conquistou a Copa do Brasil de 2008 em uma campanha memorável, marcada por:\n",
            "\n",
            "*   **Eliminação de gigantes:** O Sport eliminou o Palmeiras nas quartas de final e o Vasco da Gama na semifinal, mostrando sua força e determinação.\n",
            "*   **Final emocionante contra o Corinthians:** A final foi disputada contra o Corinthians, que na época jogava a Série B. No primeiro jogo, no Morumbi, o Sport venceu por 3 a 1. No segundo jogo, na Ilha do Retiro, o Corinthians venceu por 2 a 0, mas o Sport sagrou-se campeão pelo placar agregado de 3 a 3, com o critério do gol fora de casa a seu favor.\n",
            "*   **Destaque individual:** O atacante Carlinhos Bala foi um dos principais destaques da equipe, com gols importantes ao longo da competição.\n",
            "*   **Tática e superação:** O técnico Nelsinho Baptista montou uma equipe taticamente forte, que soube superar as dificuldades e jogar com inteligência em momentos decisivos."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Janela de Contexto e Prompt"
      ],
      "metadata": {
        "id": "PjBNy0o_cKav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Janela de Contexto é a quantidade de informação que um modelo consegue receber em uma única chamada.\n",
        "\n",
        "A unidade de informação compreendida por uma LLM é o **token**. O tamanho de um token depende do formato de tokenização do modelo.\n",
        "\n",
        "No Gemini, temos aproximadamente o seguinte:\n",
        "\n",
        "> 1 token equivale aproximadamente a 4 caracteres ou cerca de 0,75 palavras em inglês.\n",
        "> Na prática, a cada 100 tokens, temos de 60 a 80 palavras.\n",
        "\n",
        "Os modelos do Gemini tem uma janela de contexto de 1 milhão de tokens.\n",
        "\n",
        "Atenção aos [Rate Limits!](https://ai.google.dev/gemini-api/docs/rate-limits)"
      ],
      "metadata": {
        "id": "kwkowdZ2c1Oh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt-Engineering básico (spoiler)\n",
        "\n",
        "**Definir um System Prompt**\n",
        "- É importante definir um system prompt com regras globais que você deseja que o modelo sempre siga, como o propósito e algumas diretrizes.\n",
        "\n",
        "**Lost-in-the middle**\n",
        "- Se o seu prompt for muito grande, o modelo irá valorizar mais a informação de contexto que vem no início.\n",
        "\n",
        "**Recomendação do Gemini**\n",
        "- O próprio Gemini recomenda que as suas consultas/perguntas fiquem sempre ao final do prompt.\n",
        "\n",
        "**Exemplos** (zero-shots vs few-shots)\n",
        "- Busque exemplificar o raciocínio ou formato de saída para que o modelo entenda como deve responder."
      ],
      "metadata": {
        "id": "689LbEtZe291"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo um modelo de output estruturado"
      ],
      "metadata": {
        "id": "fQ5rHyQrPY26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em muitos casos é preciso definir um formato de saída específico, seja para preencher a interface de um sistema ou enviar metadados para além da resposta em um chat."
      ],
      "metadata": {
        "id": "lHHZ-wnzVICp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exemplo**: Modelo capaz de avaliar a qualidade do código do usuário."
      ],
      "metadata": {
        "id": "-8_4vJwmW3pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definição de formato de saída no contexto\n",
        "\n",
        "- Menor confiabilidade"
      ],
      "metadata": {
        "id": "B22Zs7fng67E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Avalie o meu código e me ajude a entender os problemas:\n",
        "def dividir(a, b):\n",
        "    return a / b\n",
        "\n",
        "print(dividir(10, 0))\n",
        "\n",
        "Responda de forma estruturada, em uma lista da seguinte maneira:\n",
        "[\n",
        "  {\n",
        "    \"language\": linguagem do código,\n",
        "    \"error\": campo booleano que indica se o código possui erros,\n",
        "    \"error_description\": descrição do erro,\n",
        "    \"error_line\": linha do erro,\n",
        "    \"suggestions\": sugestões de melhoria em formato de lista\n",
        "  }\n",
        "]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "V16hrUbzhBxb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=f\"{prompt}\",\n",
        ")\n",
        "# Use the response as a JSON string.\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9_uCEUChh4U",
        "outputId": "563626fc-2666-45a4-80d3-1fb33fb224b7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "  {\n",
            "    \"language\": \"python\",\n",
            "    \"error\": true,\n",
            "    \"error_description\": \"O código tenta realizar uma divisão por zero, o que é uma operação inválida e causa um `ZeroDivisionError`.\",\n",
            "    \"error_line\": 4,\n",
            "    \"suggestions\": [\n",
            "      \"Adicionar uma verificação para garantir que o denominador (b) não seja zero antes de realizar a divisão.\",\n",
            "      \"Tratar a exceção `ZeroDivisionError` usando um bloco `try...except` para evitar que o programa termine abruptamente.\",\n",
            "      \"Retornar um valor específico (como `None`, `float('inf')` ou uma mensagem de erro) quando a divisão por zero for detectada, dependendo dos requisitos da aplicação.\"\n",
            "    ]\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando Structured Outputs\n",
        "\n",
        "É possível pré-determinar uma [saída estruturada](https://ai.google.dev/gemini-api/docs/structured-output):"
      ],
      "metadata": {
        "id": "-WXYSr6Ph3rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code = \"\"\"\n",
        "def dividir(a, b):\n",
        "    return a / b\n",
        "\n",
        "print(dividir(10, 0))\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qTOtzu0SXn8h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class CodeEvaluation(BaseModel):\n",
        "    language: str\n",
        "    error: bool\n",
        "    error_description: str\n",
        "    error_line: int\n",
        "    suggestions: list[str]\n",
        "\n",
        "generation_config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=list[CodeEvaluation]\n",
        ")\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=f\"Avalie o meu código e me ajude a entender os problemas: {code}.\",\n",
        "    config=generation_config\n",
        ")\n",
        "\n",
        "print(response.text)\n",
        "\n",
        "evaluations: list[CodeEvaluation] = response.parsed"
      ],
      "metadata": {
        "id": "rNJdJaSRPWV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcf6eba-bff0-4a23-f11d-a3a848cb4772"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"language\": \"python\",\n",
            "    \"error\": true,\n",
            "    \"error_description\": \"Division by zero error. The code attempts to divide the number 10 by 0, which is mathematically undefined and results in a `ZeroDivisionError` in Python.\",\n",
            "    \"error_line\": 4,\n",
            "    \"suggestions\": [\n",
            "      \"Add a condition to check if the divisor `b` is zero before performing the division.\",\n",
            "      \"If `b` is zero, return a specific value (e.g., `None`, `float('inf')`, or raise a custom exception to indicate the error.\",\n",
            "      \"Implement error handling using a `try-except` block to catch the `ZeroDivisionError` and handle it gracefully, preventing the program from crashing.\",\n",
            "      \"Consider the context of the application and determine the appropriate behavior when division by zero is attempted. This might involve logging the error, displaying a message to the user, or attempting an alternative calculation.\"\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling"
      ],
      "metadata": {
        "id": "BszT287xiN6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os modelos Gemini são capazes de fazer chamadas a ferramentas para ampliar suas capacidades.\n",
        "\n",
        "Podem usar desde ferramentas pré-definidas (e.g. grounding, code execution) até ferramentas customizadas."
      ],
      "metadata": {
        "id": "zfhpDC5SihK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Search (Grounding)"
      ],
      "metadata": {
        "id": "ongLiyD1i_SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai.types import Tool, GenerateContentConfig, GoogleSearch\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "model_id = \"gemini-2.0-flash\"\n",
        "\n",
        "google_search_tool = Tool(\n",
        "    google_search = GoogleSearch()\n",
        ")\n",
        "\n",
        "generation_config = GenerateContentConfig(\n",
        "        tools=[google_search_tool],\n",
        "        response_modalities=[\"TEXT\"],\n",
        "    )\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_id,\n",
        "    contents=\"Quando é o próximo jogo do Brasil?\",\n",
        "    config=generation_config\n",
        ")\n",
        "\n",
        "print(response.text)\n",
        "\n",
        "# Metadados da pesquisa\n",
        "print(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya0saTyBcYCV",
        "outputId": "0cc143c5-299b-4468-d022-98b0e6e8112f",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O próximo jogo do Brasil será contra o Equador no dia 5 de junho, no Monumental de Guayaquil. Depois, o Brasil jogará contra o Paraguai no dia 10 de junho, na Neo Química Arena, em São Paulo. Ambas as partidas são válidas pelas Eliminatórias da Copa do Mundo de 2026.\n",
            "\n",
            "<style>\n",
            ".container {\n",
            "  align-items: center;\n",
            "  border-radius: 8px;\n",
            "  display: flex;\n",
            "  font-family: Google Sans, Roboto, sans-serif;\n",
            "  font-size: 14px;\n",
            "  line-height: 20px;\n",
            "  padding: 8px 12px;\n",
            "}\n",
            ".chip {\n",
            "  display: inline-block;\n",
            "  border: solid 1px;\n",
            "  border-radius: 16px;\n",
            "  min-width: 14px;\n",
            "  padding: 5px 16px;\n",
            "  text-align: center;\n",
            "  user-select: none;\n",
            "  margin: 0 8px;\n",
            "  -webkit-tap-highlight-color: transparent;\n",
            "}\n",
            ".carousel {\n",
            "  overflow: auto;\n",
            "  scrollbar-width: none;\n",
            "  white-space: nowrap;\n",
            "  margin-right: -12px;\n",
            "}\n",
            ".headline {\n",
            "  display: flex;\n",
            "  margin-right: 4px;\n",
            "}\n",
            ".gradient-container {\n",
            "  position: relative;\n",
            "}\n",
            ".gradient {\n",
            "  position: absolute;\n",
            "  transform: translate(3px, -9px);\n",
            "  height: 36px;\n",
            "  width: 9px;\n",
            "}\n",
            "@media (prefers-color-scheme: light) {\n",
            "  .container {\n",
            "    background-color: #fafafa;\n",
            "    box-shadow: 0 0 0 1px #0000000f;\n",
            "  }\n",
            "  .headline-label {\n",
            "    color: #1f1f1f;\n",
            "  }\n",
            "  .chip {\n",
            "    background-color: #ffffff;\n",
            "    border-color: #d2d2d2;\n",
            "    color: #5e5e5e;\n",
            "    text-decoration: none;\n",
            "  }\n",
            "  .chip:hover {\n",
            "    background-color: #f2f2f2;\n",
            "  }\n",
            "  .chip:focus {\n",
            "    background-color: #f2f2f2;\n",
            "  }\n",
            "  .chip:active {\n",
            "    background-color: #d8d8d8;\n",
            "    border-color: #b6b6b6;\n",
            "  }\n",
            "  .logo-dark {\n",
            "    display: none;\n",
            "  }\n",
            "  .gradient {\n",
            "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
            "  }\n",
            "}\n",
            "@media (prefers-color-scheme: dark) {\n",
            "  .container {\n",
            "    background-color: #1f1f1f;\n",
            "    box-shadow: 0 0 0 1px #ffffff26;\n",
            "  }\n",
            "  .headline-label {\n",
            "    color: #fff;\n",
            "  }\n",
            "  .chip {\n",
            "    background-color: #2c2c2c;\n",
            "    border-color: #3c4043;\n",
            "    color: #fff;\n",
            "    text-decoration: none;\n",
            "  }\n",
            "  .chip:hover {\n",
            "    background-color: #353536;\n",
            "  }\n",
            "  .chip:focus {\n",
            "    background-color: #353536;\n",
            "  }\n",
            "  .chip:active {\n",
            "    background-color: #464849;\n",
            "    border-color: #53575b;\n",
            "  }\n",
            "  .logo-light {\n",
            "    display: none;\n",
            "  }\n",
            "  .gradient {\n",
            "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
            "  }\n",
            "}\n",
            "</style>\n",
            "<div class=\"container\">\n",
            "  <div class=\"headline\">\n",
            "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
            "    </svg>\n",
            "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
            "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
            "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
            "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
            "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
            "    </svg>\n",
            "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
            "  </div>\n",
            "  <div class=\"carousel\">\n",
            "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFKWQFDGXSecikgbnwe6IpdBCKZpT0xlD6C1w33n1dDGWefsUlVjtVRnVSF17GyFjFigGecF9Po2Oii-oDbY_ke00S4h4vxOpcAN6SGCNKcO2jrc-B9MiCCaZjFIwkWuS8MZdI1jCAbPo-cYdUmPBIQlPr5TYi3Hddrhowx-VcVFsT2y-OL-MbF3irU56lcD53j1htcu6RjEmDT4kW7WQ==\">próximo jogo do Brasil</a>\n",
            "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGTPwT8aAnOMYhwONKQ8gErU9ql1ZzkW68AS2BcIX8-yYLDcHILOgFiq3hq3n32VuNjBRYOsrbBp1lfw5yfkaXLZSXbZi_2WGpgLvmiUw1V7Ak4pfjRsrIGBiYDJdtuPfdK-IxLiqbidAieDgrzl1Hc75HzHePC0CvIwrMRZT4jXJru-jpt0I4RsXKT3LwMFWwgPWJsaoD8oi_yDojjPEifD7sX5uXcjwfut2sQucJrI6MaTo9Mruoulw==\">calendário jogos da seleção brasileira</a>\n",
            "  </div>\n",
            "</div>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ferramentas Customizadas"
      ],
      "metadata": {
        "id": "031Dlit_ktSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Formato Padrão\n",
        "1. Crie a função Python\n",
        "2. Crie a definição da função\n",
        "3. Converta para o formato aceito pelo Gemini"
      ],
      "metadata": {
        "id": "f7LcocF8msuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "# Define a função que o modelo pode chamar para controlar luzes inteligentes.\n",
        "set_light_values_declaration = {\n",
        "    \"name\": \"set_light_values\",\n",
        "    \"description\": \"Sets the brightness and color temperature of a light.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"brightness\": {\n",
        "                \"type\": \"integer\",\n",
        "                \"description\": \"Light level from 0 to 100. Zero is off and 100 is full brightness\",\n",
        "            },\n",
        "            \"color_temp\": {\n",
        "                \"type\": \"string\",\n",
        "                \"enum\": [\"daylight\", \"cool\", \"warm\"],\n",
        "                \"description\": \"Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"brightness\", \"color_temp\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Esta é a função real que seria chamada com base na sugestão do modelo.\n",
        "def set_light_values(brightness: int, color_temp: str) -> dict[str, int | str]:\n",
        "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
        "\n",
        "    Args:\n",
        "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
        "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the set brightness and color temperature.\n",
        "    \"\"\"\n",
        "    return {\"brightness\": brightness, \"colorTemperature\": color_temp}"
      ],
      "metadata": {
        "id": "D5W7TihakwV4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "# Generation Config com Function Declaration\n",
        "tool = types.Tool(function_declarations=[set_light_values_declaration])\n",
        "\n",
        "# Tools também são passadas no GenerateContentConfig\n",
        "config = types.GenerateContentConfig(\n",
        "    tools=[tool]\n",
        ")\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "# Definindo as mensagens utilizando estrutura padrão.\n",
        "# Poderia ser string nesse caso\n",
        "contents = [\n",
        "    types.Content(\n",
        "        role=\"user\", parts=[types.Part(text=\"Turn the lights down to a romantic level\")]\n",
        "    )\n",
        "]\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\", config=config, contents=contents\n",
        ")\n",
        "\n",
        "# Acessando retorno da função\n",
        "print(response.candidates[0].content.parts[0].function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8tFgcoCmnJn",
        "outputId": "6d5d66f1-2fce-45ed-ce85-f2f6f62b7575"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id=None args={'brightness': 20, 'color_temp': 'warm'} name='set_light_values'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Utilizando funções diretamente (só em Python)"
      ],
      "metadata": {
        "id": "3FPf7RgDn6Wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em Python, é possível passar funções diretamente como tools, desde que a função possui docstring e type hints."
      ],
      "metadata": {
        "id": "2YkCIbH7oTZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Docstring: Descrição da função, com descrição do propósito, argumentos e retorno.\n",
        "- Type Hint: Definição dos tipos dos argumentos e da saída."
      ],
      "metadata": {
        "id": "Gjb1KgylpVTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "def get_current_temperature(location: str) -> dict:\n",
        "    \"\"\"Obtém a temperatura atual para uma determinada localização.\n",
        "\n",
        "    Args:\n",
        "        location: A cidade e o estado, e.g. Rio de Janeiro, RJ\n",
        "\n",
        "    Returns:\n",
        "        Um dicionário contendo a temperatura e a unidade.\n",
        "    \"\"\"\n",
        "    # ... (código que busca temperatura na API) ...\n",
        "    return {\"temperature\": 32, \"unit\": \"Celsius\"}\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "config = types.GenerateContentConfig(\n",
        "    tools=[get_current_temperature]\n",
        ")  # Coloque o nome da função diretamente\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=\"Qual a temperatura em Recife?\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEDIPmDgoBwO",
        "outputId": "c46ab9c4-4395-4ebd-add8-b6a91287fd86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A temperatura em Recife é de 32 graus Celsius.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Inputs Multimodais"
      ],
      "metadata": {
        "id": "Ru8hsos5qfAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para enviar diferentes formatos, deve-se fazer uso do Parts, definindo o Mime Type correto."
      ],
      "metadata": {
        "id": "a4yKQUqCqiDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dados Inline vindo de URL"
      ],
      "metadata": {
        "id": "riatsgutucfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import httpx\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "doc_url = \"https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf\"\n",
        "# Recupera e codifica o byte do PDF\n",
        "doc_data = httpx.get(doc_url).content\n",
        "\n",
        "pdf = types.Part.from_bytes(\n",
        "        data=doc_data,\n",
        "        mime_type='application/pdf',\n",
        "      )\n",
        "\n",
        "prompt = \"Resuma este documento em Português.\"\n",
        "response = client.models.generate_content(\n",
        "  model=\"gemini-2.0-flash\",\n",
        "  contents=[pdf, prompt])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6n3lhm4qhpq",
        "outputId": "41c1c293-00db-4dc6-fd89-fee25d4d7844"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Este documento apresenta o AlphaFold, um sistema de predição de estruturas de proteínas a partir de sequências de aminoácidos, baseado em aprendizado profundo (deep learning). O sistema utiliza redes neurais para prever distâncias entre pares de resíduos de aminoácidos, criando um \"potencial de força média\" que descreve a forma da proteína. Um algoritmo de gradiente descendente otimiza esse potencial, resultando em estruturas precisas sem a necessidade de procedimentos complexos de amostragem. O AlphaFold demonstrou alta precisão, mesmo com poucas sequências homólogas. Na avaliação CASP13, o AlphaFold criou estruturas de alta precisão para 24 de 43 domínios de modelagem livre, superando outros métodos. O sistema representa um avanço significativo na predição de estruturas de proteínas, com potencial para facilitar a compreensão da função e mau funcionamento de proteínas, especialmente em casos sem proteínas homólogas determinadas experimentalmente. O documento também descreve a metodologia detalhada do AlphaFold, incluindo construção de conjuntos de dados, arquitetura de redes neurais, treinamento e otimização do potencial de energia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Upload do arquivo local"
      ],
      "metadata": {
        "id": "qvecsagIueon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "# up to 20MB\n",
        "my_file = client.files.upload(file=\"path/to/sample.jpg\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[my_file, \"Legende esta imagem.\"],\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "j4t2KqDJu7vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tipos suportados:"
      ],
      "metadata": {
        "id": "I66ZF3hPsivB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Documentos](https://ai.google.dev/gemini-api/docs/document-processing?lang=python):**\n",
        "- PDF - `application/pdf`\n",
        "- JavaScript - `application/x-javascript, text/javascript`\n",
        "- Python - `application/x-python, text/x-python`\n",
        "- TXT - `text/plain`\n",
        "- HTML - `text/html`\n",
        "- CSS - `text/css`\n",
        "- Markdown - `text/md`\n",
        "- CSV - `text/csv`\n",
        "- XML - `text/xml`\n",
        "- RTF - `text/rtf`\n",
        "\n",
        "**[Imagens](https://ai.google.dev/gemini-api/docs/image-understanding):**\n",
        "- PNG - `image/png`\n",
        "- JPEG - `image/jpeg`\n",
        "- WEBP - `image/webp`\n",
        "- HEIC - `image/heic`\n",
        "- HEIF - `image/heif`\n",
        "\n",
        "**[Vídeo](https://ai.google.dev/gemini-api/docs/video-understanding):**\n",
        "- `video/mp4`\n",
        "- `video/mpeg`\n",
        "- `video/mov`\n",
        "- `video/avi`\n",
        "- `video/x-flv`\n",
        "- `video/mpg`\n",
        "- `video/webm`\n",
        "- `video/wmv`\n",
        "- `video/3gpp`\n",
        "\n",
        "**[Áudio](https://ai.google.dev/gemini-api/docs/audio):**\n",
        "- WAV - `audio/wav`\n",
        "- MP3 - `audio/mp3`\n",
        "- AIFF - `audio/aiff`\n",
        "- AAC - `audio/aac`\n",
        "- OGG Vorbis - `audio/ogg`\n",
        "- FLAC - `audio/flac`"
      ],
      "metadata": {
        "id": "LoCt51lAtl-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Links"
      ],
      "metadata": {
        "id": "Llr4a15rptwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔧 **API e Geração de Texto**\n",
        "\n",
        "* [Documentação da API (geral)](https://ai.google.dev/api?hl=pt-br&lang=python)\n",
        "* [Geração de texto com Gemini](https://ai.google.dev/gemini-api/docs/text-generation)\n",
        "* [Estratégias de prompting](https://ai.google.dev/gemini-api/docs/prompting-strategies)\n",
        "* [Geração com configuração (`GenerationConfig`)](https://ai.google.dev/api/generate-content#generationconfig)\n",
        "* [Resposta da geração (`GenerateContentResponse`)](https://ai.google.dev/api/generate-content#v1beta.GenerateContentResponse)\n",
        "* [Estrutura da configuração (`GenerationConfig` - detalhado)](https://ai.google.dev/api/generate-content#v1beta.GenerationConfig)\n",
        "\n",
        "🧠 **Entrada Multimodal e Arquivos**\n",
        "\n",
        "* [Compreensão de imagem (Image understanding)](https://ai.google.dev/gemini-api/docs/image-understanding)\n",
        "* [Upload e uso de arquivos](https://ai.google.dev/gemini-api/docs/files)\n",
        "* [Uso de contexto longo](https://ai.google.dev/gemini-api/docs/long-context)\n",
        "\n",
        "🧾 **Saída Estruturada e Function Calling**\n",
        "\n",
        "* [Saída estruturada (Structured Output)](https://ai.google.dev/gemini-api/docs/structured-output)\n",
        "* [Function Calling com Gemini](https://ai.google.dev/gemini-api/docs/function-calling)\n",
        "* [Exemplo de Function Calling automático (Python)](https://ai.google.dev/gemini-api/docs/function-calling?example=meeting#automatic_function_calling_python_only)\n",
        "\n",
        "🔗 **Grounding e Integrações Externas**\n",
        "\n",
        "* [Grounding com fontes externas](https://ai.google.dev/gemini-api/docs/grounding?lang=python)"
      ],
      "metadata": {
        "id": "-eJe8QhZqQLu"
      }
    }
  ]
}